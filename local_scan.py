import akshare as ak
import pandas as pd
from tqdm import tqdm
import time
import os
from datetime import datetime

def run_local_scan():
    print(f"ğŸš€ å¯åŠ¨æ¯æ—¥æ·±åº¦æ‰«æ | æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. è·å–ä¸­è¯500æˆä»½è‚¡æ¸…å•
    try:
        index_stock_df = ak.index_stock_cons(symbol="000905")
        stock_list = index_stock_df['å“ç§ä»£ç '].tolist()
    except Exception as e:
        print(f"âŒ è·å–æ¸…å•å¤±è´¥: {e}")
        return

    results = []
    
    # --- æ ¸å¿ƒè®¾ç½®ï¼šå¾€å‰å¤šå–ç‚¹æ•°æ®ï¼Œç¡®ä¿èƒ½ç®—å‡º 60æ—¥æ–°é«˜ ---
    start_search_date = "20250601" 

    # 2. å¼€å§‹æ‰«æ 500 åªè‚¡ç¥¨
    for i, code in enumerate(tqdm(stock_list, desc="æ‰«æä¸­è¯500æˆä»½è‚¡")):
        try:
            # æŠ“å–å†å²æ•°æ®
            df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_search_date, adjust="qfq")
            
            # æ•°æ®å¥å£®æ€§æ£€æŸ¥ï¼šè‡³å°‘è¦æœ‰ 20 å¤©æ‰èƒ½ç®— MA20
            if df is not None and len(df) >= 20:
                latest_close = df['æ”¶ç›˜'].iloc[-1]
                
                # æŒ‡æ ‡ 1: ç«™ä¸Š MA20 (çŸ­çº¿è¶‹åŠ¿)
                ma20 = df['æ”¶ç›˜'].rolling(20).mean().iloc[-1]
                is_above_ma20 = 1 if latest_close > ma20 else 0
                
                # æŒ‡æ ‡ 2: åˆ› 60æ—¥æ–°é«˜ (é•¿çº¿åŠ¨èƒ½)
                # å¦‚æœæ–°ä¸Šå¸‚ä¸æ»¡ 60 å¤©ï¼Œåˆ™å–å½“å‰æ‰€æœ‰äº¤æ˜“æ—¥çš„æœ€é«˜
                window_size = min(len(df), 60)
                high_60 = df['æœ€é«˜'].tail(window_size).max()
                is_new_high = 1 if latest_close >= high_60 else 0
                
                results.append({
                    'ma20_ok': is_above_ma20, 
                    'new_high_ok': is_new_high
                })
            
            # --- é¢‘ç‡ä¿æŠ¤ï¼šæ¯æŠ“ 100 åªæ­‡ 2 ç§’ï¼Œé˜²æ­¢è¢«æ–°æµªå° IP ---
            if i % 100 == 0 and i > 0:
                time.sleep(2)
            else:
                time.sleep(0.05)
                
        except Exception:
            # ä¸ªåˆ«è‚¡ç¥¨æŠ¥é”™åˆ™è·³è¿‡ï¼Œä¿è¯å¤§ç›˜æ•°æ®èƒ½ç®—å‡ºæ¥
            continue
    
    if not results:
        print("âŒ æ‰«æå¤±è´¥ï¼šæœªæ”¶é›†åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
        return

    # 3. è®¡ç®—ä»Šæ—¥ç™¾åˆ†æ¯”
    res_df = pd.DataFrame(results)
    today_str = datetime.now().strftime('%Y-%m-%d')
    new_data = {
        'date': [today_str],
        'ma20_ratio': [round(res_df['ma20_ok'].mean() * 100, 2)],
        'new_high_ratio': [round(res_df['new_high_ok'].mean() * 100, 2)]
    }
    new_df = pd.DataFrame(new_data)

    # --- æ ¸å¿ƒé€»è¾‘ï¼šæ™ºèƒ½è¿½åŠ ä¸è¦†ç›– ---
    file_name = "scan_results.csv"
    
    if os.path.exists(file_name):
        # 1. è¯»å–æ—§æ•°æ®
        old_df = pd.read_csv(file_name)
        # 2. åˆå¹¶æ–°æ—§æ•°æ®
        # ä½¿ç”¨ drop_duplicates æ—¶ï¼Œå¦‚æœæ—¥æœŸç›¸åŒï¼Œkeep='last' ä¼šè®©ä¸‹åˆçš„æ•°æ®è¦†ç›–ä¸­åˆçš„
        combined_df = pd.concat([old_df, new_df], ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['date'], keep='last')
        # 3. æŒ‰æ—¥æœŸæ’åºç¡®ä¿å›¾è¡¨æ­£ç¡®
        combined_df['date'] = pd.to_datetime(combined_df['date'])
        combined_df = combined_df.sort_values('date')
        combined_df['date'] = combined_df['date'].dt.strftime('%Y-%m-%d')
    else:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ç›´æ¥ä½¿ç”¨å½“å‰æ•°æ®
        combined_df = new_df

    # 4. ä¿å­˜ç»“æœ
    combined_df.to_csv(file_name, index=False)
    
    print("\n" + "="*30)
    print(f"âœ… æ‰«æä»»åŠ¡åœ†æ»¡å®Œæˆï¼")
    print(f"ğŸ“Š ä»Šæ—¥({today_str})å æ¯”ç»“æœï¼š")
    print(f"   - ç«™ä¸Š MA20 æ¯”ä¾‹: {new_data['ma20_ratio'][0]}%")
    print(f"   - åˆ› 60æ—¥æ–°é«˜æ¯”ä¾‹: {new_data['new_high_ratio'][0]}%")
    print(f"ğŸ“ ç»“æœå·²å­˜å…¥ {file_name}ï¼Œå½“å‰æ•°æ®åº“å…±ç§¯ç´¯ {len(combined_df)} å¤©æ•°æ®ã€‚")
    print("="*30)

if __name__ == "__main__":
    run_local_scan()